{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15364dd5",
   "metadata": {},
   "source": [
    "## CLIP ViT-B/32 Shape / Texture Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63d1257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import clip\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d73da732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190569b8",
   "metadata": {},
   "source": [
    "### Custom Cue-Conflicted STL-10 Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c12568a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_dataset = datasets.ImageFolder(root='data/cue_conflict_dataset', transform=preprocess)\n",
    "cc_dataset.samples.sort(key=lambda x: int(''.join(filter(str.isdigit, os.path.basename(x[0])))))\n",
    "\n",
    "cc_loader = DataLoader(\n",
    "    cc_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664a06b4",
   "metadata": {},
   "source": [
    "### Text Embeddings\n",
    "Simple Template: 'a {class}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93288f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stl10_classes = [\n",
    "    \"airplane\", \"bird\", \"car\", \"cat\", \"deer\",\n",
    "    \"dog\", \"horse\", \"monkey\",\"ship\", \"truck\"\n",
    "]\n",
    "\n",
    "all_text_features = []\n",
    "for classname in stl10_classes:\n",
    "    text = f\"a {classname}\"\n",
    "    tokenized = clip.tokenize(text).to(device)\n",
    "    text_features = model.encode_text(tokenized)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    class_feature = text_features.mean(dim=0)\n",
    "    class_feature /= class_feature.norm()\n",
    "    all_text_features.append(class_feature)\n",
    "text_features = torch.stack(all_text_features, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c43ea0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_shot_classification(loader, text_features, model, device, classes):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = [0] * len(classes)\n",
    "    class_total = [0] * len(classes)\n",
    "    class_accuracies = {}\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Encode images\n",
    "            image_features = model.encode_image(images)\n",
    "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "            # Compute similarity with text features\n",
    "            similarity = 100.0 * image_features @ text_features.to(device).T\n",
    "            preds = similarity.argmax(dim=1)\n",
    "\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i].item()\n",
    "                if preds[i].item() == label:\n",
    "                    class_correct[label] += 1\n",
    "                class_total[label] += 1\n",
    "\n",
    "    accuracy = correct / total * 100\n",
    "\n",
    "    for i, classname in enumerate(classes):\n",
    "        acc = 100.0 * class_correct[i] / class_total[i]\n",
    "        class_accuracies[classname] = acc\n",
    "\n",
    "    return accuracy, class_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d1948c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot accuracy on cue-conflicted STL-10 test set: 75.11%\n",
      "Per-class accuracy:\n",
      "    airplane  : 68.25%\n",
      "    bird      : 87.38%\n",
      "    car       : 96.50%\n",
      "    cat       : 62.12%\n",
      "    deer      : 71.38%\n",
      "    dog       : 72.62%\n",
      "    horse     : 91.00%\n",
      "    monkey    : 57.88%\n",
      "    ship      : 68.62%\n",
      "    truck     : 75.38%\n"
     ]
    }
   ],
   "source": [
    "cc_accuracy, cc_class_accuracies = zero_shot_classification(cc_loader, text_features, model, device, stl10_classes)\n",
    "\n",
    "print(f\"Zero-shot accuracy on cue-conflicted STL-10 test set: {cc_accuracy:.2f}%\")\n",
    "print(\"Per-class accuracy:\")\n",
    "for classname, acc in cc_class_accuracies.items():\n",
    "    print(f\"    {classname:10s}: {acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3be6a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP Shape Bias Result: 77.61%\n",
      "Per-class shape bias:\n",
      "    airplane  : 68.86%\n",
      "    bird      : 87.59%\n",
      "    car       : 100.78%\n",
      "    cat       : 73.74%\n",
      "    deer      : 72.74%\n",
      "    dog       : 75.56%\n",
      "    horse     : 92.27%\n",
      "    monkey    : 59.51%\n",
      "    ship      : 68.71%\n",
      "    truck     : 76.23%\n"
     ]
    }
   ],
   "source": [
    "stl_test_acc = 96.78\n",
    "stl_class_accuraries = {\n",
    "    \"airplane\"  : 99.12,\n",
    "    \"bird\"      : 99.75,\n",
    "    \"car\"       : 95.75,\n",
    "    \"cat\"       : 84.25,\n",
    "    \"deer\"      : 98.12,\n",
    "    'dog'       : 96.12,\n",
    "    \"horse\"     : 98.62,\n",
    "    \"monkey\"    : 97.25,\n",
    "    \"ship\"      : 99.88,\n",
    "    \"truck\"     : 98.88\n",
    "}\n",
    "\n",
    "clip_shape_bias = (cc_accuracy/stl_test_acc)*100\n",
    "clip_class_bias = {\n",
    "    classname: (cc_class_accuracies[classname] / stl_class_accuraries[classname]) * 100\n",
    "    for classname in cc_class_accuracies\n",
    "}\n",
    "\n",
    "\n",
    "print(f\"CLIP Shape Bias Result: {clip_shape_bias:.2f}%\")\n",
    "print(\"Per-class shape bias:\")\n",
    "for classname, rob in clip_class_bias.items():\n",
    "    print(f\"    {classname:10s}: {rob:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
